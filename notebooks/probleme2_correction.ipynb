{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problème n°2: PointNet"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certains jeux de données impliquent des nuages de points dans un espace 3D. Penser par exemple à un ensemble de mesures lidar : chaque tir permet de renseigner les coordonnées d'un des points de l'objet ciblé.\n",
        "Une tâche intéressante consiste à classer chacun des points du nuage en fonction de l'objet auquel il appartient. Cette tâche est considérée comme une variante de la segmentation sémantique d'images.\n",
        "\n",
        "Ce problème introduit à une méthode directe de segmentation d'un nuage par deep learning. Elle est basée sur une architecture particulière appelée PointNet. \\\n",
        "Dans la première partie, on présente un jeu de données (synthétisé à la volée) impliquant des nuages de points.\n",
        "Dans la seconde partie, on explore la structure et les propriétés de PointNet. Dans la troisième, on l'entraîne et dans la dernière partie, on charge les poids d'une version améliorée de PointNet (PointNet++) pour comparaison.\n",
        "\n",
        "La cellule suivante permet les imports nécessaires:"
      ],
      "metadata": {
        "id": "rPIFraX86pZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "! pip install einops\n",
        "! git clone https://github.com/nanopiero/exam_2025.git\n",
        "! cp exam_2025/utils/utils_probleme2.py .\n",
        "from utils_probleme2 import gen_pointcloud, plot_triplets"
      ],
      "metadata": {
        "id": "VMhc4--pzPdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie I : un exemple de PointCLoud data"
      ],
      "metadata": {
        "id": "OXcPslsLOKEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour construire le jeu de données, on simule un terrain couvert de deux types de bâtiments : des immeubles de forme rectangulaire aux toits plats et des igloos (dômes). Pour créer les nuages, on échantillonne les surfaces vues du ciel (les murs des bâtiments rectangulaires ne sont pas échantillonnées), en favorisant les zones d'altitude non nulles.\n",
        "Le but est de distinguer les igloos du reste (sol et toits des bâtiments). Il s'agit donc d'une segmentation binaire."
      ],
      "metadata": {
        "id": "GDqmLGFROPJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 6\n",
        "input_points, target_list, target_points  = gen_pointcloud(batch_size)\n",
        "\n",
        "\n",
        "for i in range(batch_size):\n",
        "  print(i)\n",
        "  # Représentation 3D des nuages de points et\n",
        "  # les paramètres elev et azim permettent de changer l'angle de vue\n",
        "  plot_triplets(input_points[i].transpose(0,1).cpu(),\n",
        "                elev=75, azim=0)\n",
        "\n",
        "  # Cibles : les points appartenant aux toitures d'igloos sont\n",
        "  # dans la classe 1, les autres, dans la classe 0.\n",
        "  plot_triplets(target_points[i].transpose(0,1).cpu(),\n",
        "                title='Cibles',\n",
        "                cbar_label='classe')\n",
        "\n",
        "  # Note: target_points contient non seulement les classes\n",
        "  # mais aussi les coordonnées x et y des points, pour\n",
        "  # faciliter leur visualisation"
      ],
      "metadata": {
        "id": "uBvv7mzq8SXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** A quoi correspondent les différentes dimensions de *input_points* ?"
      ],
      "metadata": {
        "id": "Ec1hdpYKWqtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_points.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MtFMDmw3Fiy",
        "outputId": "2178aa17-fe99-4fea-9215-e83a8a587658"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3, 800])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 :  taille du batch \\\n",
        "3 :  coordonnées dans l'espace \\\n",
        "800 : nb de points"
      ],
      "metadata": {
        "id": "_2YwN0gB3Ib7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Les points d'un nuage sont-ils rangés dans un ordre particulier ?"
      ],
      "metadata": {
        "id": "O29XO_-BXW3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non"
      ],
      "metadata": {
        "id": "e6pktsle3VHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** (question ouverte). Si vous deviez traiter le problème avec un FCN ou un ViT (Visual Transformer), que feriez-vous ?"
      ],
      "metadata": {
        "id": "9VdTYIGMZkYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une projection sur une grille 3D des entrées et des cibles."
      ],
      "metadata": {
        "id": "LE-EXH--3WTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie II : le modèle PointNet"
      ],
      "metadata": {
        "id": "Oi-tMb6eVseg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on s'intéresse à la propriété principale d'un réseau PointNet : l'utilisation d'opérations invariantes par rapport à l'ordre dans lequel les points sont présentés au réseau."
      ],
      "metadata": {
        "id": "ymRoRLYE1_AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_probleme2 import PointNetSegHead\n",
        "pointnet = PointNetSegHead(num_points=800, num_global_feats=1024, m=2).cuda()\n",
        "\n",
        "input_points, target_list, _ = gen_pointcloud(batch_size)\n",
        "input_points = input_points.cuda()\n",
        "output, _, _ = pointnet(input_points)"
      ],
      "metadata": {
        "id": "S04tXJXHQWJ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** La sortie du modèle PointNet correspond au premier tenseur du *tuple* fourni par la fonction *forward* de *pointnet*. A quoi correspondent les différentes dimensions de *output* ? Quel est l'effet d'une permutation des points contenus dans *inputs_points* sur la sortie ? Répondre :\n",
        "\n",
        "- en vous référant à l'article [l'article](https://arxiv.org/abs/1612.00593) qui introduit ce réseau (citer dans le texte).\n",
        "- à partir de tests à effectuer dans la cellule de code suivante (utiliser torch.randperm pour générer des permutations sur les entrées)"
      ],
      "metadata": {
        "id": "JzuMy_0l2Kbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PJqaiUh4CJ5",
        "outputId": "0135c4ac-6620-4f9e-c05d-c9e362d7ca21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 800, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 : taille du batch \\\n",
        "800 : nb de points \\\n",
        "2 : probabilités estimées pour chacune des deux classes \\\n"
      ],
      "metadata": {
        "id": "339KYOc_4DyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sur l'invariance par permutation, on a par exemple, dans l'abstract : \\\n",
        "\"*In this paper, we design a\n",
        "novel type of neural network that directly consumes point\n",
        "clouds, which well respects the permutation invariance of\n",
        "points in the input.*\""
      ],
      "metadata": {
        "id": "9VnKb6v_3xd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "permutation = torch.randperm(800)\n",
        "pointnet.eval()\n",
        "output_from_permuted_input, _, _ = pointnet(input_points[:,:, permutation])\n",
        "permuted_output = pointnet(input_points)[0][:, permutation, :]\n",
        "\n",
        "print(f'nb de composantes différentes entre output_from_permuted_input et permuted_output : {(output_from_permuted_input != permuted_output).sum()}')\n"
      ],
      "metadata": {
        "id": "99d6FryC7Bty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cca38ca-f390-494a-a5e9-b8d75ff056f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb de composantes différentes entre output_from_permuted_input et permuted_output : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** L'architecture de *pointnet* est décrite dans la Figure 2 de l'article (voir ci-dessous) évoqué à la question précédente. En dehors des opérations notées \"input transform\" et \"feature transform\", dont la compréhension est plus délicate, quelles sont les différentes opérations conduisant à une segmentation ? Que signifie le terme \"shared\" et expliquer en quoi ces opérations sont invariantes par rapport à l'ordre de présentation des points."
      ],
      "metadata": {
        "id": "9a3Ag6gf7XWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://miro.medium.com/v2/resize:fit:1100/format:webp/1*lFnrIqmV_47iRvQcY3dB7Q.png >"
      ],
      "metadata": {
        "id": "Rhf7Jzr9yJwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il y a :\n",
        "- des MLP \"partagés\" agissant sur les vecteurs associés aux points, c'est à dire qu'un même MLP est passé sur tous les vecteurs (on pouvait aussi parler de \"siamese MLP\").\n",
        "- un maxpooling est utilisé pour obtenir un \"global feature\"\n",
        "\n",
        "Comme le même MLP affecte tous les points, permuter les sorties ou permuter les entrées revient au même (notion d'équivariance, pour les curieux). Le Maxpooling étant invariant à une permutation près, et en supposant que les \"input transform\" et \"feature transform\" sont aussi équivariants, la branche du haut est invariante par rapport aux permutations et la branche du bas (notre segmentation) est équivariante."
      ],
      "metadata": {
        "id": "QqIcJMFL5dsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie III"
      ],
      "metadata": {
        "id": "6ivNzt2E86eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on se propose d'entraîner un PointNet. Pour ce faire, on utilisera une fonction de coût spécifique (voir cellule ci-dessous).\n",
        "\n",
        "**Consignes :**\n",
        "\n",
        "1) Entraîner un PointNet sur quelques centaines d'époques.\n",
        "\n",
        "2) Afficher à chaque époque la justesse des prédictions\n",
        "\n",
        "3) Charger les poids d'un réseau entraîné sur 500 époques, stockés dans le fichier **pointnet_500_ep.pth** du répertoire https://huggingface.co/nanopiero/pointnet_igloos.\n",
        "\n",
        "Visualiser les sorties de ce modèle-là en complétant le la dernière cellule de code du calepin.\n"
      ],
      "metadata": {
        "id": "Hah5_qJ78-6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PointNetSegLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=0, size_average=True, dice=False):\n",
        "        super(PointNetSegLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.size_average = size_average\n",
        "        self.dice = dice\n",
        "        # get Balanced Cross Entropy Loss\n",
        "        self.cross_entropy_loss = nn.CrossEntropyLoss(weight=self.alpha)\n",
        "\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "\n",
        "        # get Balanced Cross Entropy Loss\n",
        "        ce_loss = self.cross_entropy_loss(predictions.transpose(1, 2), targets)\n",
        "\n",
        "        # reformat predictions (b, n, c) -> (b*n, c)\n",
        "        predictions = predictions.contiguous() \\\n",
        "                                 .view(-1, predictions.size(2))\n",
        "        # get predicted class probabilities for the true class\n",
        "        pn = F.softmax(predictions)\n",
        "        pn = pn.gather(1, targets.view(-1, 1)).view(-1)\n",
        "\n",
        "        # compute loss (negative sign is included in ce_loss)\n",
        "        loss = ((1 - pn)**self.gamma * ce_loss)\n",
        "\n",
        "        if self.size_average:\n",
        "          loss = loss.mean()\n",
        "        else:\n",
        "          loss = loss.sum()\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "8cSF3sgE_TgR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt : \"I need to train a pointnet to segment a point cloud (binary segmentation). batched point clouds are generated by :\n",
        "\n",
        "input_points, target_list, _ = gen_pointcloud(64)\n",
        "\n",
        "Could you complete the following snippets to:\n",
        "\n",
        "- train the PointNet over 100 epochs.\n",
        "- display accuracy at each epoch.\""
      ],
      "metadata": {
        "id": "edaKhSJU-38K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "optimizer = torch.optim.Adam(pointnet.parameters(),\n",
        "                             lr=0.0001, betas=(0.9, 0.999))\n",
        "alpha = torch.tensor([0.5, 0.5]).cuda()\n",
        "gamma = 1\n",
        "loss_fn = PointNetSegLoss(alpha=alpha, gamma=gamma).cuda()\n",
        "batch_size = 64\n",
        "n_epochs = 100  # Train for 100 epochs\n",
        "n_batch_per_epoch = 10\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(f'Epoch {epoch}/{n_epochs}')\n",
        "    total_correct = 0\n",
        "    total_points = 0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in range(n_batch_per_epoch):\n",
        "        input_points, target_list, _ = gen_pointcloud(batch_size)\n",
        "\n",
        "        input_points = input_points.cuda()  # Move data to GPU\n",
        "        target_list = target_list.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, _, _ = pointnet(input_points)  # Forward pass\n",
        "\n",
        "        loss = loss_fn(output, target_list)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        # Compute accuracy\n",
        "        pred = output.argmax(dim=2)  # Get predicted labels\n",
        "        correct = (pred == target_list).sum().item()\n",
        "        total_correct += correct\n",
        "        total_points += target_list.numel()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_accuracy = total_correct / total_points\n",
        "    avg_loss = total_loss / n_batch_per_epoch\n",
        "    print(f'Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "CNW_PJ_aAkBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6297646-52bb-4fe2-e790-7b9d3e93428b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-2136185978dd>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pn = F.softmax(predictions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1785, Accuracy: 0.7043\n",
            "Epoch 2/100\n",
            "Loss: 0.1622, Accuracy: 0.7062\n",
            "Epoch 3/100\n",
            "Loss: 0.1547, Accuracy: 0.7159\n",
            "Epoch 4/100\n",
            "Loss: 0.1456, Accuracy: 0.7302\n",
            "Epoch 5/100\n",
            "Loss: 0.1442, Accuracy: 0.7337\n",
            "Epoch 6/100\n",
            "Loss: 0.1393, Accuracy: 0.7397\n",
            "Epoch 7/100\n",
            "Loss: 0.1382, Accuracy: 0.7475\n",
            "Epoch 8/100\n",
            "Loss: 0.1362, Accuracy: 0.7447\n",
            "Epoch 9/100\n",
            "Loss: 0.1385, Accuracy: 0.7468\n",
            "Epoch 10/100\n",
            "Loss: 0.1389, Accuracy: 0.7486\n",
            "Epoch 11/100\n",
            "Loss: 0.1288, Accuracy: 0.7551\n",
            "Epoch 12/100\n",
            "Loss: 0.1389, Accuracy: 0.7454\n",
            "Epoch 13/100\n",
            "Loss: 0.1283, Accuracy: 0.7625\n",
            "Epoch 14/100\n",
            "Loss: 0.1276, Accuracy: 0.7681\n",
            "Epoch 15/100\n",
            "Loss: 0.1296, Accuracy: 0.7580\n",
            "Epoch 16/100\n",
            "Loss: 0.1208, Accuracy: 0.7688\n",
            "Epoch 17/100\n",
            "Loss: 0.1281, Accuracy: 0.7571\n",
            "Epoch 18/100\n",
            "Loss: 0.1281, Accuracy: 0.7649\n",
            "Epoch 19/100\n",
            "Loss: 0.1288, Accuracy: 0.7574\n",
            "Epoch 20/100\n",
            "Loss: 0.1377, Accuracy: 0.7510\n",
            "Epoch 21/100\n",
            "Loss: 0.1211, Accuracy: 0.7703\n",
            "Epoch 22/100\n",
            "Loss: 0.1249, Accuracy: 0.7605\n",
            "Epoch 23/100\n",
            "Loss: 0.1248, Accuracy: 0.7703\n",
            "Epoch 24/100\n",
            "Loss: 0.1232, Accuracy: 0.7695\n",
            "Epoch 25/100\n",
            "Loss: 0.1149, Accuracy: 0.7748\n",
            "Epoch 26/100\n",
            "Loss: 0.1168, Accuracy: 0.7793\n",
            "Epoch 27/100\n",
            "Loss: 0.1215, Accuracy: 0.7742\n",
            "Epoch 28/100\n",
            "Loss: 0.1201, Accuracy: 0.7709\n",
            "Epoch 29/100\n",
            "Loss: 0.1236, Accuracy: 0.7669\n",
            "Epoch 30/100\n",
            "Loss: 0.1180, Accuracy: 0.7747\n",
            "Epoch 31/100\n",
            "Loss: 0.1126, Accuracy: 0.7768\n",
            "Epoch 32/100\n",
            "Loss: 0.1167, Accuracy: 0.7804\n",
            "Epoch 33/100\n",
            "Loss: 0.1179, Accuracy: 0.7715\n",
            "Epoch 34/100\n",
            "Loss: 0.1087, Accuracy: 0.7878\n",
            "Epoch 35/100\n",
            "Loss: 0.1255, Accuracy: 0.7664\n",
            "Epoch 36/100\n",
            "Loss: 0.1145, Accuracy: 0.7762\n",
            "Epoch 37/100\n",
            "Loss: 0.1198, Accuracy: 0.7746\n",
            "Epoch 38/100\n",
            "Loss: 0.1184, Accuracy: 0.7754\n",
            "Epoch 39/100\n",
            "Loss: 0.1126, Accuracy: 0.7814\n",
            "Epoch 40/100\n",
            "Loss: 0.1108, Accuracy: 0.7887\n",
            "Epoch 41/100\n",
            "Loss: 0.1161, Accuracy: 0.7764\n",
            "Epoch 42/100\n",
            "Loss: 0.1083, Accuracy: 0.7831\n",
            "Epoch 43/100\n",
            "Loss: 0.1041, Accuracy: 0.7904\n",
            "Epoch 44/100\n",
            "Loss: 0.1048, Accuracy: 0.7881\n",
            "Epoch 45/100\n",
            "Loss: 0.1054, Accuracy: 0.7937\n",
            "Epoch 46/100\n",
            "Loss: 0.1052, Accuracy: 0.7941\n",
            "Epoch 47/100\n",
            "Loss: 0.1099, Accuracy: 0.7834\n",
            "Epoch 48/100\n",
            "Loss: 0.1143, Accuracy: 0.7762\n",
            "Epoch 49/100\n",
            "Loss: 0.1009, Accuracy: 0.7990\n",
            "Epoch 50/100\n",
            "Loss: 0.1051, Accuracy: 0.7905\n",
            "Epoch 51/100\n",
            "Loss: 0.0932, Accuracy: 0.8031\n",
            "Epoch 52/100\n",
            "Loss: 0.0888, Accuracy: 0.8122\n",
            "Epoch 53/100\n",
            "Loss: 0.0944, Accuracy: 0.8046\n",
            "Epoch 54/100\n",
            "Loss: 0.0931, Accuracy: 0.8045\n",
            "Epoch 55/100\n",
            "Loss: 0.0917, Accuracy: 0.7999\n",
            "Epoch 56/100\n",
            "Loss: 0.0919, Accuracy: 0.8080\n",
            "Epoch 57/100\n",
            "Loss: 0.0917, Accuracy: 0.8052\n",
            "Epoch 58/100\n",
            "Loss: 0.0916, Accuracy: 0.8035\n",
            "Epoch 59/100\n",
            "Loss: 0.0893, Accuracy: 0.8059\n",
            "Epoch 60/100\n",
            "Loss: 0.0862, Accuracy: 0.8127\n",
            "Epoch 61/100\n",
            "Loss: 0.0839, Accuracy: 0.8128\n",
            "Epoch 62/100\n",
            "Loss: 0.0891, Accuracy: 0.8054\n",
            "Epoch 63/100\n",
            "Loss: 0.0978, Accuracy: 0.7921\n",
            "Epoch 64/100\n",
            "Loss: 0.0912, Accuracy: 0.8015\n",
            "Epoch 65/100\n",
            "Loss: 0.0842, Accuracy: 0.8129\n",
            "Epoch 66/100\n",
            "Loss: 0.0759, Accuracy: 0.8229\n",
            "Epoch 67/100\n",
            "Loss: 0.0826, Accuracy: 0.8116\n",
            "Epoch 68/100\n",
            "Loss: 0.0853, Accuracy: 0.8111\n",
            "Epoch 69/100\n",
            "Loss: 0.0868, Accuracy: 0.8124\n",
            "Epoch 70/100\n",
            "Loss: 0.0788, Accuracy: 0.8190\n",
            "Epoch 71/100\n",
            "Loss: 0.0847, Accuracy: 0.8158\n",
            "Epoch 72/100\n",
            "Loss: 0.0778, Accuracy: 0.8208\n",
            "Epoch 73/100\n",
            "Loss: 0.0899, Accuracy: 0.8066\n",
            "Epoch 74/100\n",
            "Loss: 0.0803, Accuracy: 0.8164\n",
            "Epoch 75/100\n",
            "Loss: 0.0799, Accuracy: 0.8191\n",
            "Epoch 76/100\n",
            "Loss: 0.0754, Accuracy: 0.8254\n",
            "Epoch 77/100\n",
            "Loss: 0.0753, Accuracy: 0.8235\n",
            "Epoch 78/100\n",
            "Loss: 0.0759, Accuracy: 0.8245\n",
            "Epoch 79/100\n",
            "Loss: 0.0759, Accuracy: 0.8263\n",
            "Epoch 80/100\n",
            "Loss: 0.0794, Accuracy: 0.8186\n",
            "Epoch 81/100\n",
            "Loss: 0.0795, Accuracy: 0.8190\n",
            "Epoch 82/100\n",
            "Loss: 0.0725, Accuracy: 0.8313\n",
            "Epoch 83/100\n",
            "Loss: 0.0750, Accuracy: 0.8300\n",
            "Epoch 84/100\n",
            "Loss: 0.0709, Accuracy: 0.8285\n",
            "Epoch 85/100\n",
            "Loss: 0.0733, Accuracy: 0.8267\n",
            "Epoch 86/100\n",
            "Loss: 0.0724, Accuracy: 0.8274\n",
            "Epoch 87/100\n",
            "Loss: 0.0727, Accuracy: 0.8295\n",
            "Epoch 88/100\n",
            "Loss: 0.0670, Accuracy: 0.8350\n",
            "Epoch 89/100\n",
            "Loss: 0.0708, Accuracy: 0.8319\n",
            "Epoch 90/100\n",
            "Loss: 0.0763, Accuracy: 0.8237\n",
            "Epoch 91/100\n",
            "Loss: 0.0820, Accuracy: 0.8146\n",
            "Epoch 92/100\n",
            "Loss: 0.0759, Accuracy: 0.8237\n",
            "Epoch 93/100\n",
            "Loss: 0.0703, Accuracy: 0.8318\n",
            "Epoch 94/100\n",
            "Loss: 0.0702, Accuracy: 0.8297\n",
            "Epoch 95/100\n",
            "Loss: 0.0702, Accuracy: 0.8330\n",
            "Epoch 96/100\n",
            "Loss: 0.0640, Accuracy: 0.8439\n",
            "Epoch 97/100\n",
            "Loss: 0.0692, Accuracy: 0.8341\n",
            "Epoch 98/100\n",
            "Loss: 0.0679, Accuracy: 0.8327\n",
            "Epoch 99/100\n",
            "Loss: 0.0687, Accuracy: 0.8320\n",
            "Epoch 100/100\n",
            "Loss: 0.0673, Accuracy: 0.8362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt : \"I need to test a trained version of the model. the weights after teraining  are stored ther :\n",
        "\n",
        "https://huggingface.co/nanopiero/pointnet_igloos\n",
        "\n",
        "And the file is called:\n",
        "\n",
        "pointnet_500_ep.pth\n",
        "\n",
        "Could you give me a snippet that'll load the weights into my pointnet ?\""
      ],
      "metadata": {
        "id": "Fq84ioGEA-nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "\n",
        "# Define the model\n",
        "pointnet = PointNetSegHead(num_points=800, num_global_feats=1024, m=2).cuda()\n",
        "pointnet.cuda()  # Move to GPU if available\n",
        "\n",
        "# URL of the weights file\n",
        "weights_url = \"https://huggingface.co/nanopiero/pointnet_igloos/resolve/main/pointnet_500_ep.pth\"\n",
        "\n",
        "# Download the weights\n",
        "weights_path = \"pointnet_500_ep.pth\"\n",
        "response = requests.get(weights_url)\n",
        "with open(weights_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Load the model weights\n",
        "checkpoint = torch.load(weights_path)\n",
        "pointnet.load_state_dict(checkpoint)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "pointnet.eval()\n",
        "\n",
        "print(\"Model weights loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KoKkaffA6Mv",
        "outputId": "23b0e0e7-d564-492d-ec8e-26ce5542b1f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-c21eb4909bcc>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(weights_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**: could you compute the accuracy of that pointnet over one epoch, and plot the results for a batch of 6, inspiring yourslef from the following snippet (targets_points mixes both coordinates and target classes)."
      ],
      "metadata": {
        "id": "gBIflMYbBh7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "pointnet.eval()\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64  # Larger batch size for efficiency\n",
        "n_batch_per_epoch = 10  # Number of batches per epoch\n",
        "\n",
        "total_correct = 0\n",
        "total_points = 0\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "for batch in range(n_batch_per_epoch):\n",
        "    # Generate a batch of point clouds\n",
        "    input_points, target_list, target_points = gen_pointcloud(batch_size)\n",
        "\n",
        "    # Move data to GPU if available\n",
        "    input_points = input_points.to(device)\n",
        "    target_points = target_points.to(device)\n",
        "\n",
        "    # Compute predictions\n",
        "    with torch.no_grad():\n",
        "        proba_pred_list, _, _ = pointnet(input_points)\n",
        "        pred_list = proba_pred_list.transpose(1, 2).max(1)[1].cpu()  # Get predicted classes\n",
        "\n",
        "    # Compute batch accuracy\n",
        "    correct = (pred_list == target_list.cpu()).sum().item()\n",
        "    total_correct += correct\n",
        "    total_points += target_list.numel()\n",
        "\n",
        "# Compute epoch accuracy\n",
        "epoch_accuracy = total_correct / total_points\n",
        "print(f\"Epoch Accuracy: {epoch_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMWXgBalEewH",
        "outputId": "7c6fa363-f6de-4df2-e2e3-882f68fed4e4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Accuracy: 0.9702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Display predictions for one batch of 6 samples\n",
        "batch_size_vis = 6  # Only visualize a small batch\n",
        "input_points_vis, _, target_points_vis = gen_pointcloud(batch_size_vis)\n",
        "\n",
        "input_points_vis = input_points_vis.to(device)\n",
        "target_points_vis = target_points_vis.to(device)\n",
        "\n",
        "# Compute predictions for visualization batch\n",
        "with torch.no_grad():\n",
        "    proba_pred_list_vis, _, _ = pointnet(input_points_vis)\n",
        "    pred_list_vis = proba_pred_list_vis.transpose(1, 2).max(1)[1].cpu()\n",
        "\n",
        "# Plot results for 6 samples\n",
        "for i in range(batch_size_vis):\n",
        "    print(f\"Sample {i}\")\n",
        "\n",
        "    # Plot input point cloud\n",
        "    plot_triplets(input_points_vis[i].transpose(0, 1).cpu(), elev=75, azim=0)\n",
        "\n",
        "    # Plot ground truth segmentation labels\n",
        "    plot_triplets(target_points_vis[i].transpose(0, 1).cpu(),\n",
        "                  title='Ground Truth',\n",
        "                  cbar_label='Class')\n",
        "\n",
        "    # Plot predicted segmentation labels\n",
        "\n",
        "    plot_triplets(torch.cat([target_points_vis[i,:2].cpu(), pred_list_vis[i].unsqueeze(0).cpu()], dim=0).transpose(0, 1).cpu(),\n",
        "                  title='Predictions',\n",
        "                  cbar_label='Class')\n"
      ],
      "metadata": {
        "id": "vae6zzRmC0Hn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}