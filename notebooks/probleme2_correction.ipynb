{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problème n°2: PointNet"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certains jeux de données impliquent des nuages de points dans un espace 3D. Penser par exemple à un ensemble de mesures lidar : chaque tir permet de renseigner les coordonnées d'un des points de l'objet ciblé.\n",
        "Une tâche intéressante consiste à classer chacun des points du nuage en fonction de l'objet auquel il appartient. Cette tâche est considérée comme une variante de la segmentation sémantique d'images.\n",
        "\n",
        "Ce problème introduit à une méthode directe de segmentation d'un nuage par deep learning. Elle est basée sur une architecture particulière appelée PointNet. \\\n",
        "Dans la première partie, on présente un jeu de données (synthétisé à la volée) impliquant des nuages de points.\n",
        "Dans la seconde partie, on explore la structure et les propriétés de PointNet. Dans la troisième, on l'entraîne et dans la dernière partie, on charge les poids d'une version améliorée de PointNet (PointNet++) pour comparaison.\n",
        "\n",
        "La cellule suivante permet les imports nécessaires:"
      ],
      "metadata": {
        "id": "rPIFraX86pZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "! pip install einops\n",
        "! git clone https://github.com/nanopiero/exam_2025.git\n",
        "! cp exam_2025/utils/utils_probleme2.py .\n",
        "from utils_probleme2 import gen_pointcloud, plot_triplets"
      ],
      "metadata": {
        "id": "VMhc4--pzPdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b022a1e-b8fb-4570-c2a5-c3a6c5a23796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Cloning into 'exam_2025'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 88 (delta 21), reused 6 (delta 6), pack-reused 45 (from 1)\u001b[K\n",
            "Receiving objects: 100% (88/88), 3.14 MiB | 7.12 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie I : un exemple de PointCLoud data"
      ],
      "metadata": {
        "id": "OXcPslsLOKEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour construire le jeu de données, on simule un terrain couvert de deux types de bâtiments : des immeubles de forme rectangulaire aux toits plats et des igloos (dômes). Pour créer les nuages, on échantillonne les surfaces vues du ciel (les murs des bâtiments rectangulaires ne sont pas échantillonnées), en favorisant les zones d'altitude non nulles.\n",
        "Le but est de distinguer les igloos du reste (sol et toits des bâtiments). Il s'agit donc d'une segmentation binaire."
      ],
      "metadata": {
        "id": "GDqmLGFROPJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 6\n",
        "input_points, target_list, target_points  = gen_pointcloud(batch_size)\n",
        "\n",
        "\n",
        "for i in range(batch_size):\n",
        "  print(i)\n",
        "  # Représentation 3D des nuages de points et\n",
        "  # les paramètres elev et azim permettent de changer l'angle de vue\n",
        "  plot_triplets(input_points[i].transpose(0,1).cpu(),\n",
        "                elev=75, azim=0)\n",
        "\n",
        "  # Cibles : les points appartenant aux toitures d'igloos sont\n",
        "  # dans la classe 1, les autres, dans la classe 0.\n",
        "  plot_triplets(target_points[i].transpose(0,1).cpu(),\n",
        "                title='Cibles',\n",
        "                cbar_label='classe')\n",
        "\n",
        "  # Note: target_points contient non seulement les classes\n",
        "  # mais aussi les coordonnées x et y des points, pour\n",
        "  # faciliter leur visualisation"
      ],
      "metadata": {
        "id": "uBvv7mzq8SXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** A quoi correspondent les différentes dimensions de *input_points* ?"
      ],
      "metadata": {
        "id": "Ec1hdpYKWqtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Les points d'un nuage sont-ils rangés dans un ordre particulier ?"
      ],
      "metadata": {
        "id": "O29XO_-BXW3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** (question ouverte). Si vous deviez traiter le problème avec un FCN ou un ViT (Visual Transformer), que feriez-vous ?"
      ],
      "metadata": {
        "id": "9VdTYIGMZkYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie II : le modèle PointNet"
      ],
      "metadata": {
        "id": "Oi-tMb6eVseg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on s'intéresse à la propriété principale d'un réseau PointNet : l'utilisation d'opérations invariantes par rapport à l'ordre dans lequel les points sont présentés au réseau."
      ],
      "metadata": {
        "id": "ymRoRLYE1_AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_probleme2 import PointNetSegHead\n",
        "pointnet = PointNetSegHead(num_points=800, num_global_feats=1024, m=2).cuda()\n",
        "\n",
        "input_points, target_list, _ = gen_pointcloud(batch_size)\n",
        "input_points = input_points.cuda()\n",
        "output, _, _ = pointnet(input_points)"
      ],
      "metadata": {
        "id": "S04tXJXHQWJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** La sortie du modèle PointNet correspond au premier tenseur du *tuple* fourni par la fonction *forward* de *pointnet*. A quoi correspondent les différentes dimensions de *output* ? Quel est l'effet d'une permutation des points contenus dans *inputs_points* sur la sortie ? Répondre :\n",
        "\n",
        "- en vous référant à l'article [l'article](https://arxiv.org/abs/1612.00593) qui introduit ce réseau (citer dans le texte).\n",
        "- à partir de tests à effectuer dans la cellule de code suivante (utiliser torch.randperm pour générer des permutations sur les entrées)"
      ],
      "metadata": {
        "id": "JzuMy_0l2Kbr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99d6FryC7Bty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** L'architecture de *pointnet* est décrite dans la Figure 2 de l'article (voir ci-dessous) évoqué à la question précédente. En dehors des opérations notées \"input transform\" et \"feature transform\", dont la compréhension est plus délicate, quelles sont les différentes opérations conduisant à une segmentation ? Que signifie le terme \"shared\" et expliquer en quoi ces opérations sont invariantes par rapport à l'ordre de présentation des points."
      ],
      "metadata": {
        "id": "9a3Ag6gf7XWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://miro.medium.com/v2/resize:fit:1100/format:webp/1*lFnrIqmV_47iRvQcY3dB7Q.png >"
      ],
      "metadata": {
        "id": "Rhf7Jzr9yJwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie III"
      ],
      "metadata": {
        "id": "6ivNzt2E86eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on se propose d'entraîner un PointNet. Pour ce faire, on utilisera une fonction de coût spécifique (voir cellule ci-dessous).\n",
        "\n",
        "**Consignes :**\n",
        "\n",
        "1) Entraîner un PointNet sur quelques centaines d'époques.\n",
        "\n",
        "2) Afficher à chaque époque la justesse des prédictions\n",
        "\n",
        "3) Charger les poids d'un réseau entraîné sur 500 époques, stockés dans le fichier **pointnet_500_ep.pth** du répertoire https://huggingface.co/nanopiero/pointnet_igloos.\n",
        "\n",
        "Visualiser les sorties de ce modèle-là en complétant le la dernière cellule de code du calepin.\n"
      ],
      "metadata": {
        "id": "Hah5_qJ78-6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PointNetSegLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=0, size_average=True, dice=False):\n",
        "        super(PointNetSegLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.size_average = size_average\n",
        "        self.dice = dice\n",
        "        # get Balanced Cross Entropy Loss\n",
        "        self.cross_entropy_loss = nn.CrossEntropyLoss(weight=self.alpha)\n",
        "\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "\n",
        "        # get Balanced Cross Entropy Loss\n",
        "        ce_loss = self.cross_entropy_loss(predictions.transpose(1, 2), targets)\n",
        "\n",
        "        # reformat predictions (b, n, c) -> (b*n, c)\n",
        "        predictions = predictions.contiguous() \\\n",
        "                                 .view(-1, predictions.size(2))\n",
        "        # get predicted class probabilities for the true class\n",
        "        pn = F.softmax(predictions)\n",
        "        pn = pn.gather(1, targets.view(-1, 1)).view(-1)\n",
        "\n",
        "        # compute loss (negative sign is included in ce_loss)\n",
        "        loss = ((1 - pn)**self.gamma * ce_loss)\n",
        "\n",
        "        if self.size_average:\n",
        "          loss = loss.mean()\n",
        "        else:\n",
        "          loss = loss.sum()\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "8cSF3sgE_TgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(pointnet.parameters(),\n",
        "                             lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "# manually set alpha weights\n",
        "alpha = torch.tensor([0.2, 0.8]).cuda()\n",
        "gamma = 1\n",
        "loss_fn = PointNetSegLoss(alpha=alpha, gamma=gamma).cuda()\n",
        "\n",
        "# exemple d'utilisation de PointNetSegLoss:\n",
        "# La transposition permet de repasser la dimension relative\n",
        "# aux probabilités en dernier, comme avec torch.nn.CrossEntropyLoss\n",
        "\n",
        "loss_fn(output.cuda(), target_list.cuda())"
      ],
      "metadata": {
        "id": "VwA_vclx0CWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "n_epochs = 200\n",
        "n_batch_per_epoch = 10\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs):\n",
        "  print('epoch : ', epoch)\n",
        "  for batch in range(1,n_batch_per_epoch):\n",
        "    ..."
      ],
      "metadata": {
        "id": "CNW_PJ_aAkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_points, target_list , target_points = gen_pointcloud(6)\n",
        "\n",
        "# Il faut construire les prédictions.\n",
        "proba_pred_list, _, _ = pointnet2.cuda()(input_points.to(device))\n",
        "pred_list = proba_pred_list.transpose(1,2).max(1)[1].cpu()\n",
        "\n",
        "# Accuracy:\n",
        "...\n",
        "# Tracé\n",
        "\n",
        "for i in range(6):\n",
        "  print(i)\n",
        "  plot_triplets(input_points[i].transpose(0,1), elev=75, azim=0)\n",
        "  plot_triplets(target_points[i].transpose(0,1),\n",
        "                title='Cibles',\n",
        "                cbar_label='classe')\n",
        "  plot_triplets(...,\n",
        "                title='Predictions',\n",
        "                cbar_label='classe')\n"
      ],
      "metadata": {
        "id": "OjFZ3ZNS-riv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}